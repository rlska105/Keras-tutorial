{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=2)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=2)\n",
    "\n",
    "y_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "y_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00137043 0.00734524 0.00986177 0.00980498 0.06306804 0.06097548\n",
      "  0.09887103 0.02048411 0.34896427 0.49234098 0.52532727 0.58456451\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05572066 0.05628175 0.12531897 0.12823046\n",
      "  0.08564414 0.11685893 0.16188645 0.16450698 0.15214521 0.1331931\n",
      "  0.14364568 0.14751763 0.55799148 0.47738943 0.42452501 0.290789\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12412375 0.47927038 0.44581287 0.39571278 0.25687242\n",
      "  0.16206279 0.15596425 0.225849   0.23462869 0.2178688  0.18633619\n",
      "  0.08036507 0.09017049 0.22432744 0.13679022 0.10541739 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04664424 0.45144384 0.46233244 0.42212254 0.28685044\n",
      "  0.19358205 0.19852844 0.23613247 0.22813551 0.2841851  0.23312613\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.27095    0.47142332 0.30447186 0.5184562\n",
      "  0.37287163 0.32901141 0.02785319 0.         0.09986717 0.29123048\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0719055  0.00505037 0.59330337\n",
      "  0.74320531 0.30073421 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.46984934\n",
      "  0.67492819 0.56889271 0.00863831 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04173804\n",
      "  0.56190421 0.77587453 0.28379624 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0818483  0.53098215 0.65107801 0.45677089 0.28073376 0.00226854\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13206871 0.53295713 0.57685821 0.55223331 0.23783708\n",
      "  0.06496971 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.096512   0.42485967 0.57197113 0.54130123\n",
      "  0.42258706 0.10696671 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03114783 0.18097958 0.47542827\n",
      "  0.61101137 0.60573036 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40179832\n",
      "  0.50232555 0.64199725 0.41721299 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08761131 0.2502981  0.34355415 0.44141464\n",
      "  0.53370022 0.5759794  0.0145111  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04522582 0.16638489 0.36321836 0.40536038 0.39090112 0.35965806\n",
      "  0.4417134  0.44357384 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.05991169 0.21035265\n",
      "  0.27783403 0.31400098 0.45195241 0.46700442 0.45522948 0.3418998\n",
      "  0.17288879 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04960961 0.14569992 0.49069994 0.43348132\n",
      "  0.30081507 0.30331038 0.44795182 0.37506861 0.15420572 0.00378645\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.04162352 0.39455464 0.41084532 0.46174438 0.47146568 0.35105011\n",
      "  0.24764503 0.19638046 0.12225296 0.01540048 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.22429931 0.36916761\n",
      "  0.46559562 0.46940295 0.34840932 0.31864842 0.31268158 0.22028809\n",
      "  0.08374208 0.00717357 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.55576501 0.50681925\n",
      "  0.45561231 0.38379326 0.226999   0.12318088 0.11219535 0.00947528\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2621 - accuracy: 0.9223\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1060 - accuracy: 0.9677\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0711 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63ad68d50>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0906 - accuracy: 0.9729\n",
      "0.09061782304663211\n",
      "0.9729\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
